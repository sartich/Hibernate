<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>This week in JBoss (8th February 2019): Happy Chinese New Year</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/p2ep2e45n1k/this-week-in-jboss-8th-february-2019-happy-chinese-new-year" /><category term="a-mq online" scheme="searchisko:content:tags" /><category term="business process management" scheme="searchisko:content:tags" /><category term="Camel" scheme="searchisko:content:tags" /><category term="codeready" scheme="searchisko:content:tags" /><category term="EAP" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="Hibernate" scheme="searchisko:content:tags" /><category term="infinispan" scheme="searchisko:content:tags" /><category term="IoT" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="news" scheme="searchisko:content:tags" /><category term="Podman" scheme="searchisko:content:tags" /><category term="redhat sso" scheme="searchisko:content:tags" /><category term="thorntail" scheme="searchisko:content:tags" /><category term="weekly_editorial" scheme="searchisko:content:tags" /><category term="weekly_update" scheme="searchisko:content:tags" /><author><name>Kevin Conner</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_8th_february_2019_happy_chinese_new_year</id><updated>2019-02-09T00:46:59Z</updated><published>2019-02-09T00:46:59Z</published><content type="html">&lt;!-- [DocumentBodyStart:d057706c-0216-41c3-9203-3823f36ee3f5] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;Welcome to the first edition of the JBoss Editorial following the recent Chinese New Year, another trip through our communities as we search for exciting pieces of news from the projects.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;IoT Edge Development and Deployment with Containers&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In the first part of a two part series Alessandro takes us on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/01/31/iot-edge-development-and-deployment-with-containers-through-openshift-part-1/" rel="nofollow"&gt;a journey exploring how we can use a Platform as a Service such as OpenShift for developing and distributing IoT edge applications, taking advantage of a container's portability&lt;/a&gt;.&amp;#160; In the second part Alessandro &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/02/05/iot-edge-development-and-deployment-with-containers-through-openshift-part-2/" rel="nofollow"&gt;extends the demo from the first part to target applications running on alternative architectures such as ARM 64&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Enabling CORS in jBPM Business Applications&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;When generating jBPM Business Applications you will discover the applications will have CORS disabled by default however this behaviour will change in the the next jBPM community release when CORS will be enabled by default.&amp;#160; In the meantime &lt;a class="jive-link-external-small" href="http://mswiderski.blogspot.com/2019/01/enabling-cors-in-your-jbpm-business.html" rel="nofollow"&gt;if you want to enable CORS in the applications you are currently generating then Tihomir demonstrates how this can be achieved&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Eric's Modern Process Integration Tooling Workshop&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Eric has been updating his &lt;a class="jive-link-external-small" href="https://bpmworkshop.gitlab.io/#/" rel="nofollow"&gt;free online rules and process automation workshop&lt;/a&gt; to the latest versions, updating JBoss BRMS to Red Hat Decision Manager and JBoss BPM Suite to Red hat process Automation Manager.&amp;#160; The entire workshop has been updated to use Decision manager 7.2, starting with &lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/01/modern-business-logic-tooling-workshop-updated-decision-manager-72.html" rel="nofollow"&gt;Lab 1 covering installation&lt;/a&gt; and &lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/02/modern-process-integration-tooling-workshop-lab3.html" rel="nofollow"&gt;Lab 3 covering the creation of Domain Models&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Kubernetes and Application Servers&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In the final article of his series comparing and contrasting Kubernetes and Application Servers, Ken &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/01/30/curse-you-choices-kubernetes-or-application-servers-part-3/" rel="nofollow"&gt;poses some questions to help you evaluate whether you should be choosing a Kubernetes solution, an Application Server or an alternative such as Thorntail&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Integrating Keycloak with Let's Encrypt&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;When testing or deploying a proof of concept using Keycloak it is common practice to choose a self signed certificate however this will raise certificate warning errors from your browser.&amp;#160; This is not the only option thanks to Certification Authorities such as &lt;a class="jive-link-external-small" href="https://letsencrypt.org/" rel="nofollow"&gt;Let's Encrypt&lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/02/06/using-a-public-certificate-with-red-hat-single-sign-on-keycloak/" rel="nofollow"&gt;enabling the automated issuing of certificates trusted by all major certificate root programs&lt;/a&gt;.&amp;#160; If you wish to &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/02/07/red-hat-single-sign-on-give-it-a-try-for-no-cost/" rel="nofollow"&gt;try this with Red Hat SSO then give it a try with a developer subscription&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Podman and Kubernetes&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The &lt;a class="jive-link-external-small" href="https://github.com/containers/libpod" rel="nofollow"&gt;Podman&lt;/a&gt; team have been playing around with the idea of transitioning local pod deployments to kubernetes and enabling these generated kubernetes configurations to be replayed within a local environment.&amp;#160; To demonstrate these capabilities Brent has written an article showing how to &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/01/29/podman-kubernetes-yaml/" rel="nofollow"&gt;move a simple nginx deployment to kubernetes and then follows with a more complex example being moved to kubernetes and back to local deployments&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Streamlining your JBoss EAP development environment with CodeReady Workspaces&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In the second part of his series discussing how to streamline your JBoss EAP development with &lt;a class="jive-link-external-small" href="https://developers.redhat.com/products/codeready-workspaces/overview/" rel="nofollow"&gt;CodeReady Workspaces&lt;/a&gt;, Laurent continues his tutorial by showing how extend the workspace from his first article to &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/01/28/codeready-workspaces-streamline-jboss-eap-development-part2/" rel="nofollow"&gt;include commands for building and running a JBoss EAP project, using this to deploy and debug the application and finally how to configure a factory to allow your work to be shared with others collaborating on your project&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Hacking on A-MQ Online&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Christina was recently invited by the EnMasse team to hack on their new A-MQ Online platform, their self service messaging platform which allows an application developer/user to quickly spin up their own queues and topics.&amp;#160; Following the experience Christina &lt;a class="jive-link-external-small" href="http://wei-meilin.blogspot.com/2019/01/amq-online-101-what-ive-learnt-from.html" rel="nofollow"&gt;wrote down her take on the basics and recorded a couple of videos describing A-MQ Online in more detail&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Developing Cloud Native Microservices using Apache Camel&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Claus recently gave an hour long webinar where he &lt;a class="jive-link-external-small" href="http://www.davsclaus.com/2019/01/webinar-develop-cloud-native.html" rel="nofollow"&gt;demonstrated how to leverage the Enterprise Integration Patterns best practices within kubernetes through the development of Camel based microservices and the serverless capabilities if the upcoming Camel 3.0 release&lt;/a&gt;.&amp;#160; The webinar has already taken place however the recording is available through the on demand service.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Hibernate Community Newsletter&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In &lt;a class="jive-link-external-small" href="http://in.relation.to/2019/02/01/hibernate-community-newsletter-2019-03/" rel="nofollow"&gt;Hibernate Community Newsletter 03/2019&lt;/a&gt; we find articles discussing how to handle SQL reserved keywords for database identifiers such as table or column names, how to integrate JPA and Hibernate with Spring Boot, supporting the wide variety of column types in PostgreSQL, how to map one-to-one relationships and how to map many-to-many relationships with additional columns.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;New Releases&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The &lt;a class="jive-link-external-small" href="http://infinispan.org/" rel="nofollow"&gt;Infinispan&lt;/a&gt; team have announced the release of&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://blog.infinispan.org/2019/01/1000alpha3-and-946final.html" rel="nofollow"&gt;Infinispan 9.4.6.Final and Infinispan 10.0.0.Alpha3.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://blog.infinispan.org/2019/01/infinispan-spring-boot-starter-213final.html" rel="nofollow"&gt;Infinispan Spring Boot Starter 2.1.3.Final.&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;The &lt;a class="jive-link-external-small" href="http://hibernate.org/" rel="nofollow"&gt;Hibernate&lt;/a&gt; team have announced the release of &lt;a class="jive-link-external-small" href="http://in.relation.to/2019/02/01/hibernate-search-6-0-0-Alpha2-and-5-11-1-Final/" rel="nofollow"&gt;Hibernate Search 6.0.0.Alpha2 and Hibernate Search 5.11.1.Final.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;The &lt;a class="jive-link-external-small" href="http://jbpm.org/" rel="nofollow"&gt;jBPM&lt;/a&gt; team have announced the release of &lt;a class="jive-link-external-small" href="http://mswiderski.blogspot.com/2019/02/jbpm-visual-studio-extension-new.html" rel="nofollow"&gt;jBPM Visual Studio Extension 0.6.0.&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;That's all we have time for in this edition of the JBoss Editorial, join us again next time when we will take another trip through our communities in search of more news, articles and releases.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:d057706c-0216-41c3-9203-3823f36ee3f5] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/p2ep2e45n1k" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the first edition of the JBoss Editorial following the recent Chinese New Year, another trip through our communities as we search for exciting pieces of news from the projects.   IoT Edge Development and Deployment with Containers   In the first part of a two part series Alessandro takes us on a journey exploring how we can use a Platform as a Service such as OpenShift for developing an...</summary><dc:creator>Kevin Conner</dc:creator><dc:date>2019-02-09T00:46:59Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2019/02/08/this-week-in-jboss-8th-february-2019-happy-chinese-new-year</feedburner:origLink></entry><entry><title>Red Hat Single Sign-On: Give it a try for no cost!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/o4QYByyNyQk/" /><category term="authentication" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="OpenShift Enterprise by Red Hat" scheme="searchisko:content:tags" /><category term="Red Hat JBoss Core Services Collection" scheme="searchisko:content:tags" /><category term="Red Hat Middleware Core Services Collections" scheme="searchisko:content:tags" /><category term="red hat single sign-on" scheme="searchisko:content:tags" /><category term="Red Hat SSO" scheme="searchisko:content:tags" /><category term="security" scheme="searchisko:content:tags" /><author><name>Nicolas Massé</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_single_sign_on_give_it_a_try_for_no_cost</id><updated>2019-02-07T13:00:45Z</updated><published>2019-02-07T13:00:45Z</published><content type="html">&lt;p&gt;In a software world where each day is more hostile than the previous one, security matters and developers are coping with more and more non-functional requirements about security. The most common ones are the &amp;#8220;OWASP Top 10&amp;#8221;: the ten security risks that every developer should know. There are many more security risks you should care about, but those ten risks are the ones having the most impact on the security of your software. Among them are authentication and access control.&lt;/p&gt; &lt;p class="p1"&gt;The good news is that authentication and access control are now commodities in the open source world, thanks to Red Hat Single Sign-On Red Hat Single Sign-On is an access management tool that takes care of the details of most authentication protocols such as SAML, OAuth, and OpenID Connect; user consent with UMA; and even access control. It is easy to use, is very well-documented, and has a &lt;a href="https://www.keycloak.org/"&gt;very active community: Keycloak&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article describes how to download and install Red Hat Single Sign-On for no cost.&lt;/p&gt; &lt;p&gt;&lt;span id="more-558097"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Why not give it a try?&lt;/h2&gt; &lt;p&gt;Red Hat Single Sign-On is part of the Red Hat Middleware Core Services Collections (formerly called Red Hat JBoss Core Services Collection), and this means it is shipped and supported with &lt;a href="https://www.redhat.com/en/resources/jboss-core-services-collection-datasheet"&gt;OpenShift and most products of the Red Hat middleware portfolio&lt;/a&gt;. If you are already using those products in your company, chances are &lt;a href="https://access.redhat.com/articles/2294961"&gt;you can already use and deploy Red Hat Single Sign-On&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Alternatively, as a developer, you can also try Red Hat Single Sign-On through a developer subscription at no cost. If you already have a developer account, go to &lt;a href="https://developers.redhat.com/"&gt;developers.redhat.com&lt;/a&gt;, click &amp;#8220;Log in&amp;#8221; in the upper right corner, and log in.&lt;/p&gt; &lt;h2&gt;Register for a developer subscription&lt;/h2&gt; &lt;p&gt;If you don&amp;#8217;t already have a developer subscription, go to &lt;a href="https://developers.redhat.com/register"&gt;developers.redhat.com/register&lt;/a&gt; and create your account.&lt;/p&gt; &lt;h2&gt;Create a token to access the Red Hat registry&lt;/h2&gt; &lt;p&gt;You will need to create a token to be able to fetch Red Hat Single Sign-On from the Red Hat registry. Go to &lt;a href="https://access.redhat.com/terms-based-registry/"&gt;access.redhat.com/terms-based-registry&lt;/a&gt;, log in with your developer account (if you have not already done so), and click &amp;#8220;New Service Account.&amp;#8221;&lt;/p&gt; &lt;p&gt;Give the token a name (for the rest of this article, we will use &amp;#8220;sso&amp;#8221;) and a meaningful description.&lt;/p&gt; &lt;p&gt;Click &amp;#8220;Create&amp;#8221; and the generated token is displayed. Save the username and the token in a safe place for future reference.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.21.31-1.png"&gt;&lt;img class=" aligncenter wp-image-558177 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.21.31-1-1024x538.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.21.31-1-1024x538.png" alt=" Generating a token" width="640" height="336" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.21.31-1-1024x538.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.21.31-1-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.21.31-1-768x404.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Click the &amp;#8220;OpenShift Secret&amp;#8221; tab and then &amp;#8220;sso-secret.yaml&amp;#8221; to download your token in a format OpenShift will understand. Save it somewhere convenient for later use.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.22.50.png"&gt;&lt;img class=" aligncenter wp-image-558157 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.22.50-1024x516.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.22.50-1024x516.png" alt="Download your token" width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.22.50-1024x516.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.22.50-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/02/Screen-Shot-2019-02-01-at-16.22.50-768x387.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Install Red Hat Single Sign-On&lt;/h2&gt; &lt;p&gt;To install Red Hat Single Sign-On, you will need an OpenShift instance. If your company has one, use it. If not, I would recommend using &lt;a href="https://developers.redhat.com/products/cdk/overview/"&gt;Red Hat Container Development Kit (CDK)&lt;/a&gt;/minishift. &lt;a href="https://docs.okd.io/latest/minishift/getting-started/index.html"&gt;Minishift&lt;/a&gt; is an OpenShift installation targeted at developers that runs on your laptop. If you need to install CDK/minishift, see &lt;a href="https://developers.redhat.com/products/cdk/hello-world/#fndtn-windows"&gt;these instructions&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Spin up a minishift instance:&lt;/p&gt; &lt;pre&gt;$ minishift start&lt;/pre&gt; &lt;p&gt;Create a new project for your Red Hat Single Sign-On deployment:&lt;/p&gt; &lt;pre&gt;$ oc new-project sso&lt;/pre&gt; &lt;p&gt;Inject the token you downloaded previously in your OpenShift project, as a secret:&lt;/p&gt; &lt;pre&gt;$ oc create -f ~/Downloads/*_sso-secret.yaml&lt;/pre&gt; &lt;p&gt;Find the name of your secret:&lt;/p&gt; &lt;pre&gt;$ oc get secret NAME                       TYPE                                  DATA      AGE 10072637-sso-pull-secret   kubernetes.io/dockerconfigjson        1         3m&lt;/pre&gt; &lt;p&gt;If you named your token &amp;#8220;sso&amp;#8221; as suggested above, your secret should end with &amp;#8220;-sso-pull-secret.&amp;#8221; In this example, my secret is named &amp;#8220;10072637-sso-pull-secret.&amp;#8221;&lt;/p&gt; &lt;p&gt;Link your token with the default service account so that any pod in this project can use it (do not forget to change &amp;#8220;10072637-sso-pull-secret&amp;#8221; to your token name):&lt;/p&gt; &lt;pre&gt;$ oc secrets link default 10072637-sso-pull-secret --for=pull&lt;/pre&gt; &lt;p&gt;And import the Red Hat Single Sign-On 7.3 image into your project:&lt;/p&gt; &lt;pre&gt;$ oc import-image redhat-sso73-openshift:1.0 --confirm --scheduled --from=registry.redhat.io/redhat-sso-7/sso73-openshift:1.0&lt;/pre&gt; &lt;p&gt;You can now deploy Red Hat Single Sign-On 7.3 as explained in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.3/html/red_hat_single_sign-on_for_openshift/get_started"&gt;documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Are you eager to see Red Hat Single Sign-On live but you do not want to read the documentation? Here is a summary:&lt;/p&gt; &lt;pre&gt;$ oc create -f https://raw.githubusercontent.com/jboss-container-images/redhat-sso-7-openshift-image/sso73-dev/templates/sso73-x509-https.json $ oc policy add-role-to-user view system:serviceaccount:$(oc project -q):default $ oc new-app --template=sso73-x509-https -p SSO_ADMIN_USERNAME=admin -p SSO_ADMIN_PASSWORD=password -p IMAGE_STREAM_NAMESPACE=$(oc project -q)&lt;/pre&gt; &lt;p&gt;Wait a couple of minutes for minishift to pull the image and start the pod. You can supervise the deployment with the following command (press Ctrl-C to exit):&lt;/p&gt; &lt;pre&gt;$ oc get pods -w&lt;/pre&gt; &lt;p&gt;Once deployed, display the console URL using this command:&lt;/p&gt; &lt;pre&gt;$ oc get route sso -o jsonpath='http://{.spec.host}/auth/admin/'&lt;/pre&gt; &lt;p&gt;Open this URL in your web browser and log in with the username and password you provided during installation (admin/password, in this example).&lt;/p&gt; &lt;p&gt;Congratulations; you just installed Red Hat Single Sign-On!&lt;/p&gt; &lt;h2&gt;Further reading&lt;/h2&gt; &lt;p&gt;To get the most value out of Red Hat Single Sign-On, see the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.3/html/server_administration_guide/"&gt;Server Administration Guide&lt;/a&gt; and the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.3/html/securing_applications_and_services_guide/"&gt;Securing Applications and Services Guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You might also wish to read &lt;a href="https://developers.redhat.com/blog/2019/02/06/using-a-public-certificate-with-red-hat-single-sign-on-keycloak"&gt;Using a public certificate with Red Hat Single Sign-On/Keycloak&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Happy testing!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#38;linkname=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F07%2Fred-hat-single-sign-on-give-it-a-try-for-no-cost%2F&amp;#038;title=Red%20Hat%20Single%20Sign-On%3A%20Give%20it%20a%20try%20for%20no%20cost%21" data-a2a-url="https://developers.redhat.com/blog/2019/02/07/red-hat-single-sign-on-give-it-a-try-for-no-cost/" data-a2a-title="Red Hat Single Sign-On: Give it a try for no cost!"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/02/07/red-hat-single-sign-on-give-it-a-try-for-no-cost/"&gt;Red Hat Single Sign-On: Give it a try for no cost!&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/o4QYByyNyQk" height="1" width="1" alt=""/&gt;</content><summary>In a software world where each day is more hostile than the previous one, security matters and developers are coping with more and more non-functional requirements about security. The most common ones are the “OWASP Top 10”: the ten security risks that every developer should know. There are many more security risks you should care about, but those ten risks are the ones having the most impact on t...</summary><dc:creator>Nicolas Massé</dc:creator><dc:date>2019-02-07T13:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/02/07/red-hat-single-sign-on-give-it-a-try-for-no-cost/</feedburner:origLink></entry><entry><title>Red Hat Summit 2019 - New microservice pitfalls session accepted</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/9-uPwHn8dKg/red-hat-summit-2019-new-microservices-pitfalls.html" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_summit_2019_new_microservice_pitfalls_session_accepted</id><updated>2019-02-11T05:53:15Z</updated><published>2019-02-07T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://www.redhat.com/en/summit/2019" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" target="_blank"&gt;&lt;img alt="red hat summit 2018" border="0" data-original-height="449" data-original-width="1600" height="89" src="https://3.bp.blogspot.com/-GgSA_VtNlM4/W9scMmE44vI/AAAAAAAAtPg/JLVfBeaUx6Er5HdXs8biI-N1vbFNl0rsQCLcBGAs/s320/Screenshot%2B2018-11-01%2Bat%2B15.09.12.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;a href="https://www.schabell.org/2018/11/red-hat-summit-2019-submitting-pitfalls-storytelling-career-planning.html" target="_blank"&gt;Previously I mentioned&lt;/a&gt; that I'd submitted together with colleagues sessions on a diverse range of topics for Red Hat Summit 2019.&lt;br /&gt;&lt;br /&gt;The next Red Hat Summit 2019 will be in Boston, MA from 7-9 May. The theme is expand your possibilities and should be an interesting time to expand your knowledge along with your network.&lt;br /&gt;&lt;br /&gt;Acceptance letters arrived and I'll be seeing you in Boston soon with the following session.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;Last year with my good friend &lt;a href="https://twitter.com/roelhodzelmans?lang=en" target="_blank"&gt;Roel Hodzelmans&lt;/a&gt;, we presented session that was pretty popular and ended up in the top 10% of all Red Hat Summit 2018.&lt;br /&gt;&lt;br /&gt;The rest of 2018 we spent our time touring various venues, conferences, customers and partners to share the story behind &lt;i&gt;3 pitfalls everyone should avoid with hybrid multicloud&lt;/i&gt;. Attendees everywhere asked us if there were more pitfalls and we have listened.&lt;br /&gt;&lt;br /&gt;While the follow up session on this hybrid multicloud talk did not get accepted, we'll be sharing our pitfalls insights around customers efforts with microservices.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;3 Pitfalls Everyone Should Avoid with Microservices&lt;/h3&gt;&lt;a href="https://2.bp.blogspot.com/-O-_mBjtmODQ/W-7UxnwOf0I/AAAAAAAAtTE/e05cMSQ8UfMqydnPwy1UxbNHYn5-4cNMgCLcBGAs/s1600/Screenshot%2B2018-11-16%2Bat%2B15.31.16.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img border="0" data-original-height="281" data-original-width="866" height="64" src="https://2.bp.blogspot.com/-O-_mBjtmODQ/W-7UxnwOf0I/AAAAAAAAtTE/e05cMSQ8UfMqydnPwy1UxbNHYn5-4cNMgCLcBGAs/s200/Screenshot%2B2018-11-16%2Bat%2B15.31.16.png" width="200" /&gt;&lt;/a&gt;&lt;i&gt;The daily hype is all around you. Microservices are a necessary step along the path to integration for a digitally successful future for your organization. The choices you’ve got to make don’t preclude the daily work of enhancing your customer’s experiences. From containers, cloud, multicloud, and beyond, microservices are the core infrastructure ensuring your organization's&amp;nbsp;flexibility in the digital world. Join us for an hour of power, where real customer experiences are used to highlight the three top lessons as they transitioned their integration infrastructure into modern day microservices.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;See you all there in Boston at Red Hat Summit 2019!&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=f-d1v1mjvwo:2AuqPNg6I4k:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=f-d1v1mjvwo:2AuqPNg6I4k:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=f-d1v1mjvwo:2AuqPNg6I4k:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=f-d1v1mjvwo:2AuqPNg6I4k:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=f-d1v1mjvwo:2AuqPNg6I4k:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/f-d1v1mjvwo" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/9-uPwHn8dKg" height="1" width="1" alt=""/&gt;</content><summary>Previously I mentioned that I'd submitted together with colleagues sessions on a diverse range of topics for Red Hat Summit 2019. The next Red Hat Summit 2019 will be in Boston, MA from 7-9 May. The theme is expand your possibilities and should be an interesting time to expand your knowledge along with your network. Acceptance letters arrived and I'll be seeing you in Boston soon with the followin...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-02-07T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/f-d1v1mjvwo/red-hat-summit-2019-new-microservices-pitfalls.html</feedburner:origLink></entry><entry><title>Using a public certificate with Red Hat Single Sign-On/Keycloak</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/wKs3rOwGhsE/" /><category term="certificate" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="lego" scheme="searchisko:content:tags" /><category term="Let's Encrypt" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="red hat single sign-on" scheme="searchisko:content:tags" /><category term="Red Hat SSO" scheme="searchisko:content:tags" /><category term="security" scheme="searchisko:content:tags" /><category term="single sign-on" scheme="searchisko:content:tags" /><category term="sso" scheme="searchisko:content:tags" /><author><name>Nicolas Massé</name></author><id>searchisko:content:id:jbossorg_blog-using_a_public_certificate_with_red_hat_single_sign_on_keycloak</id><updated>2019-02-06T13:00:56Z</updated><published>2019-02-06T13:00:56Z</published><content type="html">&lt;p&gt;When deploying &lt;a href="https://developers.redhat.com/blog/category/sso/"&gt;Red Hat Single Sign-On&lt;/a&gt;/&lt;a href="https://developers.redhat.com/blog/tag/keycloak/"&gt;Keycloak&lt;/a&gt; for a test or a proof of concept, most users will choose to use a self-signed certificate as explained in &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html-single/red_hat_single_sign-on_for_openshift/index" rel="nofollow"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The setup instructions are straightforward, but this self-signed certificate will trigger certificate error messages in your web browser and can also prevent some clients such as Postman from working properly.&lt;/p&gt; &lt;p&gt;This article explains how to use a public certificate from &lt;a href="https://letsencrypt.org/"&gt;Let&amp;#8217;s Encrypt&lt;/a&gt; with Red Hat Single Sign-On.&lt;/p&gt; &lt;p&gt;&lt;span id="more-557897"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Are you using a public certificate?&lt;/h2&gt; &lt;p&gt;A simple and effective way to know if you are using a public certificate is to use &lt;code&gt;curl&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;$ curl https://sso.example.test/auth/realms/master curl: (60) SSL certificate problem: self signed certificate in certificate chain More details here: https://curl.haxx.se/docs/sslcerts.html curl performs SSL certificate verification by default, using a "bundle" of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn't adequate, you can specify an alternate file using the --cacert option. If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL). If you'd like to turn off curl's verification of the certificate, use the -k (or --insecure) option. HTTPS-proxy has similar options --proxy-cacert and --proxy-insecure.&lt;/pre&gt; &lt;p&gt;If you get this output from &lt;code&gt;curl&lt;/code&gt;, you are using a self-signed certificate that will cause you headaches later.&lt;/p&gt; &lt;p&gt;Continue reading to learn how to fix this!&lt;/p&gt; &lt;h2&gt;Instructions&lt;/h2&gt; &lt;p&gt;During the rest of this article, we will focus on a Red Hat Single Sign-On 7.2 installation on &lt;a href="http://openshift.com/"&gt;OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I assume Red Hat Single Sign-On has been installed, as explained in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html-single/red_hat_single_sign-on_for_openshift/index#getting_started" rel="nofollow"&gt;official documentation&lt;/a&gt; using one of the &amp;#8220;sso72-x509-*&amp;#8221; templates.&lt;/p&gt; &lt;p&gt;First, move to the project in which you installed Red Hat Single Sign-On:&lt;/p&gt; &lt;pre&gt;$ oc project sso&lt;/pre&gt; &lt;p&gt;We will retrieve a public certificate using &lt;a href="https://letsencrypt.org/" rel="nofollow"&gt;Let&amp;#8217;s Encrypt&lt;/a&gt; as a certificate authority, and &lt;a href="https://github.com/xenolf/lego"&gt;Lego&lt;/a&gt; is a client that can speak with Let&amp;#8217;s Encrypt. It has several advantages such as ease of use and it&amp;#8217;s packaged as a container image.&lt;/p&gt; &lt;p&gt;Install Lego in the current project:&lt;/p&gt; &lt;pre&gt;$ oc new-app --name lego xenolf/lego:latest $ oc patch dc lego --type=json -p '[{"op": "add", "path": "/spec/template/spec/containers/0/command", "value": ["/bin/sh", "-c", "while :; do sleep 1; done" ]}]' $ oc expose dc/lego --port=8080 &lt;/pre&gt; &lt;p&gt;To get a public certificate for your Red Hat Single Sign-On instance, we need to find the hostname of that instance. The hostname is a property of the OpenShift route that has been created as part of the Red Hat Single Sign-On installation.&lt;/p&gt; &lt;p&gt;Query the hostname of your Red Hat Single Sign-On route and save it for later use:&lt;/p&gt; &lt;pre&gt;$ hostname=$(oc get route sso -o jsonpath='{.spec.host}') &lt;/pre&gt; &lt;p&gt;This route to your Red Hat Single Sign-On instance needs to be replaced by a temporary route to Lego so that Let&amp;#8217;s Encrypt can perform the HTTP challenge. The easiest way to do this is to delete your existing route and create a new one with the same hostname:&lt;/p&gt; &lt;pre&gt;$ oc delete route sso $ oc expose service lego --hostname="$hostname" --name=sso &lt;/pre&gt; &lt;p&gt;You can now trigger the certificate request from the running Lego pod:&lt;/p&gt; &lt;pre&gt;$ pod=$(oc get pods -o name -l app=lego |head -n1) $ oc rsh $pod lego --path /tmp/.lego --http :8080 -x dns-01 -x tls-alpn-01 -d "$hostname" -m your@email.address --accept-tos run&lt;/pre&gt; &lt;p&gt;The first command gets the name of the pod running Lego and sets a shell variable accordingly. The second command runs the &lt;code&gt;lego&lt;/code&gt; command from the Lego container. This command has several switches:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;--path /tmp/.lego&lt;/code&gt; will store the generated certificates in &lt;code&gt;/tmp&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;--http :8080&lt;/code&gt; asks Lego to listen on port 8080 to receive the &lt;a href="https://letsencrypt.org/how-it-works/" rel="nofollow"&gt;ACME HTTP challenge&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-x dns-01 -x tls-alpn-01&lt;/code&gt; disables the other challenges that cannot succeed in our environment.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-d "$hostname"&lt;/code&gt; sets the hostname of our Red Hat Single Sign-On instance in the certificate request.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-m your@email.address&lt;/code&gt; sets the email address to receive renewal notifications (do not forget to set yours!).&lt;/li&gt; &lt;li&gt;&lt;code&gt;--accept-tos&lt;/code&gt; means you read and accepted the &lt;a href="https://acme-v01.api.letsencrypt.org/terms" rel="nofollow"&gt;Let&amp;#8217;s Encrypt Terms of Service&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;run&lt;/code&gt; triggers the certificate request.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you did everything correctly, you should see something like this:&lt;/p&gt; &lt;pre&gt;2019/01/22 12:03:55 [INFO] [hostname] acme: Obtaining bundled SAN certificate 2019/01/22 12:03:56 [INFO] [hostname] AuthURL: https://acme-v02.api.letsencrypt.org/acme/authz/[redacted] 2019/01/22 12:03:56 [INFO] [hostname] acme: Could not find solver for: tls-alpn-01 2019/01/22 12:03:56 [INFO] [hostname] acme: Trying to solve HTTP-01 2019/01/22 12:03:56 [INFO] [hostname] Served key authentication 2019/01/22 12:04:01 [INFO] [hostname] The server validated our request 2019/01/22 12:04:01 accept tcp [::]:8080: use of closed network connection 2019/01/22 12:04:01 [INFO] [hostname] acme: Validations succeeded; requesting certificates 2019/01/22 12:04:03 [INFO] [hostname] Server responded with a certificate. &lt;/pre&gt; &lt;p&gt;Congratulations; you just issued your first public certificate!&lt;/p&gt; &lt;p&gt;Retrieve the freshly issued certificate from the Lego container and store it somewhere safe:&lt;/p&gt; &lt;pre&gt;$ oc rsync $pod:/tmp/.lego ~/ &lt;/pre&gt; &lt;p&gt;You should now have the certificate stored in your home folder on your workstation.&lt;/p&gt; &lt;pre&gt;$ find ~/.lego/certificates /Users/redhat/.lego/certificates /Users/redhat/.lego/certificates/&amp;#60;hostname&amp;#62;.key /Users/redhat/.lego/certificates/&amp;#60;hostname&amp;#62;.issuer.crt /Users/redhat/.lego/certificates/&amp;#60;hostname&amp;#62;.json /Users/redhat/.lego/certificates/&amp;#60;hostname&amp;#62;.crt&lt;/pre&gt; &lt;p&gt;You can now delete the temporary route and replace it with a new to route to the Red Hat Single Sign-On pod.&lt;/p&gt; &lt;pre&gt;$ oc delete route sso $ oc create -f - &amp;#60;&amp;#60;EOF apiVersion: v1 kind: Route metadata: name: sso spec: host: $hostname to: kind: Service name: sso tls: termination: edge key: |- $(sed 's/^/ /' ~/.lego/certificates/$hostname.key) certificate: |- $(sed 's/^/ /' ~/.lego/certificates/$hostname.crt) caCertificate: |- $(sed 's/^/ /' ~/.lego/certificates/$hostname.issuer.crt) EOF&lt;/pre&gt; &lt;p&gt;Confirm that your Red Hat Single Sign-On instance is now using a public certificate by running again the &lt;code&gt;curl&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;$ curl https://$hostname/auth/realms/master &lt;/pre&gt; &lt;p&gt;Lego does not need to run continuously, so between certificate renewals (every 90 days), you can scale it down:&lt;/p&gt; &lt;pre&gt;$ oc scale dc/lego --replicas=0 &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Self-signed certificates are always a headache when delivering a proof of concept or a workshop. This article presented a very practical way to get a valid public certificate for your Red Hat Single Sign-On instance.&lt;/p&gt; &lt;p&gt;Some aspects would need improvements to be used for longer periods or in production environments. For instance, we would need to use the proper &lt;a href="https://developers.redhat.com/blog/category/kubernetes/"&gt;Kubernetes&lt;/a&gt; concepts, &lt;a href="https://docs.openshift.com/container-platform/latest/dev_guide/jobs.html" rel="nofollow"&gt;Job&lt;/a&gt; and &lt;a href="https://docs.openshift.com/container-platform/latest/dev_guide/cron_jobs.html" rel="nofollow"&gt;Cron&lt;/a&gt; to run Lego, handle the certificate renewal, and use the DNS validation challenge (which requires a more complex setup but does not involve deleting the &lt;code&gt;sso&lt;/code&gt; route).&lt;/p&gt; &lt;p&gt;Also, this article is about getting public certificates for your Red Hat Single Sign-On instance that is publicly deployed on the Internet. If your instance is deployed on your laptop for development purposes, &lt;a href="https://blog.filippo.io/mkcert-valid-https-certificates-for-localhost/" rel="nofollow"&gt;the &lt;code&gt;mkcert&lt;/code&gt;project&lt;/a&gt; can help you generate proper certificates and make them trusted in your web browser.&lt;/p&gt; &lt;p&gt;Nevertheless, I hope this article will give you ideas and entice you to use public certificates for your Red Hat Single Sign-On setups.&lt;/p&gt; &lt;p&gt;Another article that might be of interest is &amp;#8220;&lt;a href="https://developers.redhat.com/blog/2018/03/19/sso-made-easy-keycloak-rhsso/"&gt;Single Sign-On Made Easy with Keycloak/Red Hat SSO&lt;/a&gt;.&amp;#8221;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#38;linkname=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F06%2Fusing-a-public-certificate-with-red-hat-single-sign-on-keycloak%2F&amp;#038;title=Using%20a%20public%20certificate%20with%20Red%20Hat%20Single%20Sign-On%2FKeycloak" data-a2a-url="https://developers.redhat.com/blog/2019/02/06/using-a-public-certificate-with-red-hat-single-sign-on-keycloak/" data-a2a-title="Using a public certificate with Red Hat Single Sign-On/Keycloak"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/02/06/using-a-public-certificate-with-red-hat-single-sign-on-keycloak/"&gt;Using a public certificate with Red Hat Single Sign-On/Keycloak&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/wKs3rOwGhsE" height="1" width="1" alt=""/&gt;</content><summary>When deploying Red Hat Single Sign-On/Keycloak for a test or a proof of concept, most users will choose to use a self-signed certificate as explained in the official documentation. The setup instructions are straightforward, but this self-signed certificate will trigger certificate error messages in your web browser and can also prevent some clients such as Postman from working properly. This arti...</summary><dc:creator>Nicolas Massé</dc:creator><dc:date>2019-02-06T13:00:56Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/02/06/using-a-public-certificate-with-red-hat-single-sign-on-keycloak/</feedburner:origLink></entry><entry><title>Open Source and Deforestation</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Ezt8L186n60/open-source-and-deforestation.html" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_ofbizian" scheme="searchisko:content:tags" /><category term="open source" scheme="searchisko:content:tags" /><category term="sustainability" scheme="searchisko:content:tags" /><author><name>Bilgin Ibryam</name></author><id>searchisko:content:id:jbossorg_blog-open_source_and_deforestation</id><updated>2019-02-08T13:19:18Z</updated><published>2019-02-05T21:43:00Z</published><content type="html">&lt;i&gt;Follow me on&lt;a href="http://twitter.com/bibryam" target="_blank"&gt; twitter&lt;/a&gt; for other posts in this space. If you prefer, read the same post on &lt;a href="https://medium.com/@bibryam/open-source-and-deforestation-65f1dc69c435" target="_blank"&gt;Medium&lt;/a&gt;.&lt;/i&gt;&lt;br /&gt;&lt;h3&gt;Open source is like a forest&lt;/h3&gt;A forest is a complex ecosystem of plants, animals microorganisms, non-living material, all balanced delicately by nature. It requires the right geography, the right soil, the right amount of rain and sun, and decades to build a forest.&lt;br /&gt;&lt;br /&gt;So is open source. An open source project is a delicate ecosystem of contributors, reviewer, users, supporting organizations, all balanced by a feeling of a community. It requires the right ideas at the right time, the right group of developers, the right technology, an enormous amount of dedication and passion, and years to build a project.&lt;br /&gt;&lt;br /&gt;Forests are home for many species, the source of oxygen, clean water, and air, prevent floods block winds, source of wood when used in a sustainable manner. Forests offer endless benefits to many when consumed responsibly and without destroying it completely.&lt;br /&gt;&lt;br /&gt;So is open source. Open source is the place where newbies learn to collaborate, communicate and code. It is the place where experienced innovate, standardize and distribute cutting edge software. It is the place where remote developers scratch their itch, &lt;a href="http://oss.fund/" target="_blank"&gt;get paid&lt;/a&gt;, and the result benefits everybody. The open source model provides the foundations of the digital infrastructure of modern human life.&lt;br /&gt;&lt;h3&gt;Deforestation&lt;/h3&gt;In the late 1960s, the deforestation of the Amazon (not the company, but the rainforest) started at an enormous rate. Trees were cleared, lands were transformed. The delicately balanced rain forests were destroyed unrecoverably leading to varying degrees of loss of soil, erosion, landslides, climate change, and even change the patterns of weather. And some companies captured enormous value from &lt;a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons" target="_blank"&gt;destroying the commons&lt;/a&gt; of nature by cutting the trees for wood and fuel in an unsustainable manner.&lt;br /&gt;&lt;br /&gt;&lt;div style="text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-_h7SHQT4DOw/XFoCRhCy98I/AAAAAAAAMIE/c4jiClkcdwY4T7ekLUU6sCrQR-8dW1x_QCLcBGAs/s1600/440px-Lacanja_burn.JPG"&gt;&lt;img border="0" src="https://4.bp.blogspot.com/-_h7SHQT4DOw/XFoCRhCy98I/AAAAAAAAMIE/c4jiClkcdwY4T7ekLUU6sCrQR-8dW1x_QCLcBGAs/s400/440px-Lacanja_burn.JPG" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style="text-align: center;"&gt;&lt;i&gt;Tragedy of the commons image by Wikipedia&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;Today, open source is the latest battleground that could have consequences similar to &lt;a href="https://www.fordfoundation.org/about/library/reports-and-studies/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure"&gt;deforestation&lt;/a&gt;. It is a battleground of business models, a battleground of small against large, of consultancy and tool producers against large cloud service providers.&lt;br /&gt;&lt;br /&gt;On one hand, there are the small companies employing open source developers to build and maintain open source projects and become de facto consultancy and tooling provider around that technology. The open source model helps attract customers for the small businesses and they contribute back their work in return. It is a win-win for free riders, paying customers, maintainers, and the open source projects continue getting wider adoption.&lt;br /&gt;&lt;br /&gt;But enterprise customers don’t want consultancy or tooling, they want to use technology in a fast, scalable, reliable and secure way and focus their resources on the business domain instead. And this is what cloud services offer. If that premise is true, any widespread open source technology will eventually be &lt;a href="https://www.linkedin.com/pulse/open-source-needs-protect-itself-from-service-wrappers-greg-luck/"&gt;wrapped&lt;/a&gt; as a cloud service, and companies will prefer to use it there rather than running themselves in-house with the help of consultancy or proprietary automation tools.&lt;br /&gt;&lt;br /&gt;That leaves small companies benefiting from and contributing to open source, out of business. As Thomas Dinsmore said it on Twitter “It’s impossible to argue that software should be open AND the originators have the sole right to monetize. If you believe in the latter, the solution is commercial software. With a license key.”. Any company benefiting from the open source model is also accepting the risk of being eaten by a large cloud service provider eventually. These are the &lt;a href="https://stratechery.com/2019/aws-mongodb-and-the-economic-realities-of-open-source/"&gt;rules of the open source&lt;/a&gt; game, and they are fair.&lt;br /&gt;&lt;br /&gt;That makes the future of these open source project unclear. When technology is offered as a cloud service, the smaller companies start protecting their investments by introducing additional licenses and moving away from being truly open source. We have seen that with Redis, MongoDB, Kafka, and others to follow eventually. That also means the small companies will have less incentive to develop the open source project beyond the open core elements and instead will focus more effort on their non-open source value adding competitive edges.&lt;br /&gt;&lt;br /&gt;As for the cloud providers, they are not obliged to sustain open source by license, not forced by their business model either. If a project stagnates, loses contributors and users, a cloud provider could quicker than anybody jump into the next popular project and offer that as a service. That is likely to lead to a change of dynamics of contributors from small and mid-range companies to individuals (as these early &lt;a href="https://www.itwire.com/open-source/84888-debian-leader-forks-redis-modules-that-are-under-commons-clause-licence.html" target="_blank"&gt;indications&lt;/a&gt; around Redis) or new &lt;a href="https://aws.amazon.com/blogs/opensource/supporting-apache-software-foundation/"&gt;active&lt;/a&gt; on the open source arena cloud providers. This is a new reality, and we are yet to see how open source adapts to it.&lt;br /&gt;&lt;h3&gt;A sustainable future&lt;/h3&gt;The mightiest corporations of our times capture enormous value by using the commons of the open source community, by wrapping the projects into services and offering them for the cost of hardware usage. While benefiting from open source unconditionally and without any expectations is perfectly fine according to the license agreements and the rules of capitalism, benefiting without contributing back a fair share, nor helping for sustainability, has the effects of deforestation of the ecosystem. In the absence of a sustainable model, the delicate balance of contributors and users can be easily broken, leading to confusion, fear, license changes, leading to multi-license projects, leading to discouraged contributors, leading to cautious users, changing the open source model as we all know it, irreversibly.&lt;br /&gt;&lt;br /&gt;The good news is that the software industry is increasingly getting more educated on understanding how open source works, what it takes to produce, and sustain it. With recent reactions on social media, we can see that there is no legal, but moral expectation from the companies benefitting from open source most, to play their equal part in sustaining the same open source by being exemplary with their actions, and not only exploit the commons the other contributors are building and the whole society is relying upon.&lt;br /&gt;&lt;br /&gt;Today, every household has something made of wood. We can keep it that way by sustaining our forests. Every business depends on something made of open source. We can keep it that way by sustaining our open source ecosystem.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Ezt8L186n60" height="1" width="1" alt=""/&gt;</content><summary>Follow me on twitter for other posts in this space. If you prefer, read the same post on Medium. Open source is like a forestA forest is a complex ecosystem of plants, animals microorganisms, non-living material, all balanced delicately by nature. It requires the right geography, the right soil, the right amount of rain and sun, and decades to build a forest. So is open source. An open source proj...</summary><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2019-02-05T21:43:00Z</dc:date><feedburner:origLink>http://www.ofbizian.com/2019/02/open-source-and-deforestation.html</feedburner:origLink></entry><entry><title>IoT edge development and deployment with containers through OpenShift: Part 2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yFg4PldcTEw/" /><category term="AArch64" scheme="searchisko:content:tags" /><category term="arm" scheme="searchisko:content:tags" /><category term="arm64" scheme="searchisko:content:tags" /><category term="CDK" scheme="searchisko:content:tags" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="container" scheme="searchisko:content:tags" /><category term="Container Development Kit" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="edge deployment" scheme="searchisko:content:tags" /><category term="edge development" scheme="searchisko:content:tags" /><category term="fedora" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Gateway" scheme="searchisko:content:tags" /><category term="Internet of Things" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="Podman" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Alessandro Arrichiello</name></author><id>searchisko:content:id:jbossorg_blog-iot_edge_development_and_deployment_with_containers_through_openshift_part_2</id><updated>2019-02-05T13:00:49Z</updated><published>2019-02-05T13:00:49Z</published><content type="html">&lt;p&gt;In the &lt;a href="https://developers.redhat.com/blog/2019/01/31/iot-edge-development-and-deployment-with-containers-through-openshift-part-1"&gt;first part of this series&lt;/a&gt;, we saw how effective a platform as a service (PaaS) such as &lt;a href="http://openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt; is for developing IoT edge applications and distributing them to remote sites, thanks to &lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;containers&lt;/a&gt; and &lt;a href="https://www.redhat.com/en/technologies/management/ansible"&gt;Red Hat Ansible Automation&lt;/a&gt; technologies.&lt;/p&gt; &lt;p&gt;Usually, we think about IoT applications as something specially designed for low power devices with limited capabilities.  IoT devices might use a different CPU architectures or platform. For this reason, we tend to use completely different technologies for IoT application development than for services that run in a data center.&lt;/p&gt; &lt;p&gt;In part two, we explore some techniques that allow you to build and test contains for alternate architectures such as ARM64 on an x86_64 host.  The goal we are working towards is to enable you to use the same language, framework, and development tools for code that runs in your datacenter or all the way out to IoT edge devices. In this article, I&amp;#8217;ll show building and running an AArch64 container image on an x86_64 host and then building an RPI3 image to run it on physical hardware using Fedora and &lt;a href="https://developers.redhat.com/blog/tag/podman/"&gt;Podman&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-556897"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;In the previous article, I assumed as a prerequisite that an IoT gateway may be capable of running x86_64 containers, but unfortunately, this is not a common use case due to the various type of IoT gateways available today on the market.&lt;/p&gt; &lt;p&gt;I discovered a very interesting project named “multiarch” with multiple repositories &lt;a href="https://github.com/multiarch"&gt;available on GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The aim of the project is to create a handy way for using a built-in Linux kernel feature named &lt;code&gt;binfmt_misc&lt;/code&gt;, which is explained in Wikipedia as follows: “&lt;i&gt;binfmt_misc is a capability of the Linux kernel which allows arbitrary executable file formats to be recognized and passed to certain user space applications, such as emulators and virtual machines. It is one of a number of binary format handlers in the kernel that are involved in preparing a user-space program to run.&lt;/i&gt;”&lt;/p&gt; &lt;p&gt;The concepts behind the multiarch project are really simple: Imagine launching a privileged container that is able to interact with the containers’ host and use the &lt;code&gt;binfmt_misc&lt;/code&gt; feature for informing the kernel that some other binary’s handlers are available somewhere in the &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Are you guessing about the handlers? They are just QEMU x86_64 executables capable of running the specific architecture binaries: ARM, MIPS, Power, etc.&lt;/p&gt; &lt;p&gt;Keep in mind that QEMU is a generic and open source machine emulator and virtualizer, so it’s the right candidate for this job. It is also used for running KVM virtual machines with near-native performance.&lt;/p&gt; &lt;p&gt;At this point, the only thing you have to do is to place the right QEMU binaries in the containers with a different architecture. Why must they be placed in the containers?&lt;/p&gt; &lt;p&gt;The QEMU executables must be placed in the containers because when the container engine tries to execute some other ARCH binaries, it will trigger in the kernel the &lt;code&gt;binfmt_misc&lt;/code&gt; feature, which will then redirect this execution to the binary in the path we specified. Due to the fact that we’re in the container&amp;#8217;s virtual root filesystem, the QEMU executable must reside in the same environment of the binary that just ran.&lt;/p&gt; &lt;p&gt;The feature activation is really simple. As the multiarch project page states, we need only ensure that &lt;code&gt;multiarch/qemu-user-static:register&lt;/code&gt; with the &lt;code&gt;--reset&lt;/code&gt; option is used.&lt;/p&gt; &lt;p&gt;The project page suggests using Docker for applying this action and, of course, this feature will be lost on the next machine’s restart, but we can set it as a one-shot &lt;code&gt;systemd&lt;/code&gt; service.&lt;/p&gt; &lt;p&gt;For this article, we’re just using a Minishift installation. For this reason, due to the lack of persistence of Minishift’s base operating system, we’ll just run the Docker command once we have logged in:&lt;/p&gt; &lt;pre&gt;[alex@lenny ~]$ cdk-minishift ssh [docker@minishift ~]$ docker run --rm --privileged multiarch/qemu-user-static:register --reset Setting /usr/bin/qemu-alpha-static as binfmt interpreter for alpha Setting /usr/bin/qemu-arm-static as binfmt interpreter for arm Setting /usr/bin/qemu-armeb-static as binfmt interpreter for armeb Setting /usr/bin/qemu-sparc32plus-static as binfmt interpreter for sparc32plus Setting /usr/bin/qemu-ppc-static as binfmt interpreter for ppc Setting /usr/bin/qemu-ppc64-static as binfmt interpreter for ppc64 Setting /usr/bin/qemu-ppc64le-static as binfmt interpreter for ppc64le Setting /usr/bin/qemu-m68k-static as binfmt interpreter for m68k Setting /usr/bin/qemu-mips-static as binfmt interpreter for mips Setting /usr/bin/qemu-mipsel-static as binfmt interpreter for mipsel Setting /usr/bin/qemu-mipsn32-static as binfmt interpreter for mipsn32 Setting /usr/bin/qemu-mipsn32el-static as binfmt interpreter for mipsn32el Setting /usr/bin/qemu-mips64-static as binfmt interpreter for mips64 Setting /usr/bin/qemu-mips64el-static as binfmt interpreter for mips64el Setting /usr/bin/qemu-sh4-static as binfmt interpreter for sh4 Setting /usr/bin/qemu-sh4eb-static as binfmt interpreter for sh4eb Setting /usr/bin/qemu-s390x-static as binfmt interpreter for s390x Setting /usr/bin/qemu-aarch64-static as binfmt interpreter for aarch64 Setting /usr/bin/qemu-aarch64_be-static as binfmt interpreter for aarch64_be Setting /usr/bin/qemu-hppa-static as binfmt interpreter for hppa Setting /usr/bin/qemu-riscv32-static as binfmt interpreter for riscv32 Setting /usr/bin/qemu-riscv64-static as binfmt interpreter for riscv64 Setting /usr/bin/qemu-xtensa-static as binfmt interpreter for xtensa Setting /usr/bin/qemu-xtensaeb-static as binfmt interpreter for xtensaeb Setting /usr/bin/qemu-microblaze-static as binfmt interpreter for microblaze Setting /usr/bin/qemu-microblazeel-static as binfmt interpreter for microblazeel&lt;/pre&gt; &lt;p&gt;As you saw in the previous command, we just registered for the current x86_64 host a bunch of handlers that will receive specific requests for different architectures’ instructions from the host’s kernel.&lt;/p&gt; &lt;p&gt;We’re now ready to test a container build project with an architecture other than x86_64.&lt;/p&gt; &lt;p&gt;For this reason, I prepared a simple test project for building an ARM 64-bit container image and using it with a Raspberry Pi 3: it’s just a web server.&lt;/p&gt; &lt;p&gt;As you’ll see in the &lt;a href="https://github.com/alezzandro/test-arm-container"&gt;project page&lt;/a&gt;, the git repo contains just a Dockerfile:&lt;/p&gt; &lt;pre&gt;FROM multiarch/debian-debootstrap:arm64-stretch-slim RUN apt-get update RUN apt-get install -y apache2 RUN sed -i 's/80/8080/g' /etc/apache2/ports.conf EXPOSE 8080 CMD ["/usr/sbin/apache2ctl", "-DFOREGROUND"]&lt;/pre&gt; &lt;p&gt;It starts from a Debian base image with an ARM64 architecture. It updates the APT repos and installs a web server. After that, it replaces the default listening port and then it sets the right &lt;code&gt;init&lt;/code&gt; command.&lt;/p&gt; &lt;p&gt;I bet you’re asking, &amp;#8220;Where is the magic?&amp;#8221;&lt;/p&gt; &lt;p&gt;Well, the magic happens thanks to &lt;code&gt;/usr/bin/qemu-aarch64-static&lt;/code&gt;, which is available in the container image itself. This binary is an x86_64 binary, different from all the others that are AArch64. The Linux Kernel will forward AArch64 binaries executions to this handler!&lt;/p&gt; &lt;p&gt;We’re now ready to create the project and the OpenShift resources for handling the container image’s build:&lt;/p&gt; &lt;pre&gt;[alex@lenny ~]$ oc new-project test-arm-project Now using project "test-arm-project" on server "https://192.168.42.213:8443". [alex@lenny ~]$ oc new-app https://github.com/alezzandro/test-arm-container --&amp;#62; Found Docker image 4734ae4 (3 days old) from Docker Hub for "multiarch/debian-debootstrap:arm64-stretch-slim"    * An image stream tag will be created as "debian-debootstrap:arm64-stretch-slim" that will track the source image    * A Docker build using source code from https://github.com/alezzandro/test-arm-container will be created      * The resulting image will be pushed to image stream tag "test-arm-container:latest"      * Every time "debian-debootstrap:arm64-stretch-slim" changes a new build will be triggered    * This image will be deployed in deployment config "test-arm-container"    * Port 8080/tcp will be load balanced by service "test-arm-container"      * Other containers can access this service through the hostname "test-arm-container"    * WARNING: Image "multiarch/debian-debootstrap:arm64-stretch-slim" runs as the 'root' user which may not be permitted by your cluster administrator --&amp;#62; Creating resources ...    imagestream.image.openshift.io "debian-debootstrap" created    imagestream.image.openshift.io "test-arm-container" created    buildconfig.build.openshift.io "test-arm-container" created    deploymentconfig.apps.openshift.io "test-arm-container" created    service "test-arm-container" created --&amp;#62; Success    Build scheduled, use 'oc logs -f bc/test-arm-container' to track its progress.    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:     'oc expose svc/test-arm-container'    Run 'oc status' to view your app.&lt;/pre&gt; &lt;p&gt;Looking over the OpenShift web interface, we can see that the container image was successfully built and it’s also running:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-046-OpenShift-Web-Console_-https___192.168.42.213_8443_consol.png"&gt;&lt;img class=" aligncenter wp-image-556907 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-046-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-1024x492.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-046-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-1024x492.png" alt="The running container image" width="640" height="308" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-046-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-1024x492.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-046-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-300x144.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-046-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-768x369.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We can even access the running container and try to execute some commands:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-047-OpenShift-Web-Console_-https___192.168.42.213_8443_consol.png"&gt;&lt;img class=" aligncenter wp-image-556917 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-047-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-1024x492.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-047-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-1024x492.png" alt="Executing some commands" width="640" height="308" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-047-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-1024x492.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-047-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-300x144.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/FireShot-Capture-047-OpenShift-Web-Console_-https___192.168.42.213_8443_consol-768x369.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;As you can see from the previous command, we attached to the running container and we verified that every command is proxied through &lt;code&gt;/usr/bin/qemu-aarch64-static&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We also checked that the binaries are truly the AArch64 architecture.&lt;/p&gt; &lt;p&gt;We can now try the just-built container image on a Raspberry Pi 3. I chose as the base operating system Fedora ARM Linux.&lt;/p&gt; &lt;p&gt;First, I set up one SD card with an easy-to-use tool after I downloaded the image from &lt;a href="https://arm.fedoraproject.org/"&gt;Fedora’s website&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;[alex@lenny Downloads]$ sudo arm-image-installer --addkey=/home/alex/.ssh/id_rsa.pub --image=/home/alex/Downloads/Fedora-Minimal-29-1.2.aarch64.raw.xz --relabel --resizefs --norootpass --target=rpi3 --media=/dev/sda [sudo] password for alex: *********************************************************** ** WARNING: You have requested the image be written to sda. ** /dev/sda is usually the root filesystem of the host. *********************************************************** ** Do you wish to continue? (type 'yes' to continue) *********************************************************** = Continue? yes ===================================================== = Selected Image:                                  = /home/alex/Downloads/Fedora-Minimal-29-1.2.aarch64.raw.xz = Selected Media : /dev/sda = U-Boot Target : rpi3 = SELinux relabel will be completed on first boot. = Root Password will be removed. = Root partition will be resized = SSH Public Key /home/alex/.ssh/id_rsa.pub will be added. ===================================================== ... = Raspberry Pi 3 Uboot is already in place, no changes needed. = Removing the root password. = Adding SSH key to authorized keys. = Touch /.autorelabel on rootfs. = Installation Complete! Insert into the rpi3 and boot.&lt;/pre&gt; &lt;p&gt;While our brand new Raspberry Pi 3 operating system will boots, we can export the Docker image from the running Minishift virtual machine.&lt;/p&gt; &lt;p&gt;We’ll connect directly to the VM and run a &lt;code&gt;docker save&lt;/code&gt; command. We can use this trick because we’re in a demo environment; in a real use-case scenario, we may export the internal OpenShift registry to let external devices connect.&lt;/p&gt; &lt;pre&gt;[alex@lenny ~]$ cdk-minishift ssh Last login: Thu Jan 24 19:15:36 2019 from 192.168.42.1 [docker@minishift ~]$ docker save -o test-arm-container.tar 172.30.1.1:5000/test-arm-project/test-arm-container:latest [alex@lenny Downloads]$ scp -i ~/.minishift/machines/minishift/id_rsa docker@`cdk-minishift ip`/home/docker/test-arm-container.tar&lt;/pre&gt; &lt;p&gt;We can then push the image to the Raspberry Pi and install Podman for running it!&lt;/p&gt; &lt;p&gt;Don’t know what Podman is? Read more about &lt;a href="https://developers.redhat.com/blog/2018/08/29/intro-to-podman/"&gt;Podman, which is in Red Hat Enterprise Linux&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;[alex@lenny Downloads]$ scp test-arm-container.tar root@192.168.1.52:/root/test-arm-container.tar                              100% 214MB 450.1KB/s 08:07 [alex@lenny Downloads]$ ssh root@192.168.1.52 [root@localhost ~]# cat /etc/fedora-release Fedora release 29 (Twenty Nine) [root@localhost ~]# uname -a Linux localhost.localdomain 4.19.15-300.fc29.aarch64 #1 SMP Mon Jan 14 16:22:13 UTC 2019 aarch64 aarch64 aarch64 GNU/Linux [root@localhost ~]# dnf install -y podman &lt;/pre&gt; &lt;p&gt;Then we load the container image and finally run it:&lt;/p&gt; &lt;pre&gt;[root@localhost ~]# podman load -i test-arm-container.tar Getting image source signatures Copying blob 36a049148cc6: 104.31 MiB / 104.31 MiB [=====================] 1m34s Copying blob d56ce20a3f9c: 15.20 MiB / 15.20 MiB [=======================] 1m34s Copying blob cf01d69beeaf: 94.53 MiB / 94.53 MiB [=======================] 1m34s Copying blob 115c696bd46d: 3.00 KiB / 3.00 KiB [=========================] 1m34s Copying config 478a2361357e: 5.46 KiB / 5.46 KiB [==========================] 0s Writing manifest to image destination Storing signatures Loaded image(s): 172.30.1.1:5000/arm-project/test-arm-container:latest [root@localhost ~]# podman images REPOSITORY                                       TAG IMAGE ID CREATED SIZE 172.30.1.1:5000/arm-project/test-arm-container   latest 478a2361357e 4 hours ago 224 MB [root@localhost ~]# podman run -d 172.30.1.1:5000/arm-project/test-arm-container:latest cdbf0ac43a2dd01afd73220d5756060665df0b72a43bd66bf865d1c6149f325f [root@localhost ~]# podman ps CONTAINER ID  IMAGE                                         COMMAND CREATED STATUS PORTS  NAMES cdbf0ac43a2d  172.30.1.1:5000/arm-project/test-arm-container:latest  /usr/sbin/apache2... 6 seconds ago Up 5 seconds ago       pedantic_agnesi &lt;/pre&gt; &lt;p&gt;We can then test the web server:&lt;/p&gt; &lt;pre&gt;[root@localhost ~]# podman inspect cdbf0ac43a2d | grep -i address            "LinkLocalIPv6Address": "",            "SecondaryIPAddresses": null,            "SecondaryIPv6Addresses": null,            "GlobalIPv6Address": "",            "IPAddress": "10.88.0.7",            "MacAddress": "1a:c8:30:a4:be:2f" [root@localhost ~]# curl 10.88.0.7:8080 2&amp;#62;/dev/null | head &amp;#60;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&amp;#62; &amp;#60;html xmlns="http://www.w3.org/1999/xhtml"&amp;#62;  &amp;#60;head&amp;#62;    &amp;#60;meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /&amp;#62;    &amp;#60;title&amp;#62;Apache2 Debian Default Page: It works&amp;#60;/title&amp;#62;    &amp;#60;style type="text/css" media="screen"&amp;#62;  * {    margin: 0px 0px 0px 0px;    padding: 0px 0px 0px 0px;&lt;/pre&gt; &lt;p&gt;Finally, let’s also check the content and compare the binaries in the container with ones in the Raspberry Pi:&lt;/p&gt; &lt;pre&gt;[root@localhost ~]# podman run -ti 172.30.1.1:5000/arm-project/test-arm-container:latest /bin/bash root@8e39d1c28259:/# root@8e39d1c28259:/# id uid=0(root) gid=0(root) groups=0(root) root@8e39d1c28259:/# uname -a Linux 8e39d1c28259 4.19.15-300.fc29.aarch64 #1 SMP Mon Jan 14 16:22:13 UTC 2019 aarch64 GNU/Linux root@8e39d1c28259:/# cat /etc/debian_version 9.6 root@8e39d1c28259:/# file /bin/bash /bin/bash: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 3.7.0, BuildID[sha1]=29b2624b1e147904a979d91daebc60c27ac08dc6, stripped root@8e39d1c28259:/# exit [root@localhost ~]# file /bin/bash /bin/bash: ELF 64-bit LSB shared object, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 3.7.0, BuildID[sha1]=25dee020ab8f6525bd244fb3f9082a47e940b1e6, stripped, too many notes (256)&lt;/pre&gt; &lt;p&gt;We just saw that we can run this container with Podman. So why not apply some techniques we saw in past articles about Podman and its integration with &lt;code&gt;systemd&lt;/code&gt;? &lt;img src="https://s.w.org/images/core/emoji/2.4/72x72/1f642.png" alt="" class="wp-smiley" style="height: 1em; max-height: 1em;" /&gt;&lt;/p&gt; &lt;p&gt;Read more about Podman and &lt;a href="https://developers.redhat.com/blog/2018/11/29/managing-containerized-system-services-with-podman/"&gt;managing containerized system services&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/01/31/iot-edge-development-and-deployment-with-containers-through-openshift-part-1/"&gt;IoT edge development and deployment with containers through OpenShift: Part 1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/01/15/podman-managing-containers-pods/"&gt;Podman: Managing pods and containers in a local container runtime&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/29/managing-containerized-system-services-with-podman/"&gt;Managing containerized system services with Podman&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/20/buildah-podman-containers-without-daemons/"&gt;Containers without daemons: Podman and Buildah available in RHEL 7.6 and RHEL 8 Beta&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools/"&gt;Podman – The next generation of Linux container tools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/08/29/intro-to-podman/"&gt;Intro to Podman (New in Red Hat Enterprise Linux 7.6)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/23/customizing-an-openshift-ansible-playbook-bundle/"&gt;Customizing an OpenShift Ansible Playbook Bundle&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;That&amp;#8217;s all. I hope you enjoyed this IoT solution!&lt;/p&gt; &lt;h2&gt;About Alessandro&lt;/h2&gt; &lt;p class="selectionShareable"&gt;&lt;img class="bio-img-display" src="https://developers.redhat.com/blog/wp-content/uploads/2018/05/profile_picture-300x300.jpg" alt="Alessandro Arrichiello" align="left" /&gt;&lt;/p&gt; &lt;p class="author-info selectionShareable"&gt;Alessandro Arrichiello is a Solution Architect for Red Hat Inc. He has a passion for GNU/Linux systems, which began at age 14 and continues today. He has worked with tools for automating enterprise IT: configuration management and continuous integration through virtual platforms. He’s now working on distributed cloud environments involving PaaS (OpenShift), IaaS (OpenStack) and Processes Management (CloudForms), Containers building, instances creation, HA services management, and workflow builds.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#38;linkname=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F05%2Fiot-edge-development-and-deployment-with-containers-through-openshift-part-2%2F&amp;#038;title=IoT%20edge%20development%20and%20deployment%20with%20containers%20through%20OpenShift%3A%20Part%202" data-a2a-url="https://developers.redhat.com/blog/2019/02/05/iot-edge-development-and-deployment-with-containers-through-openshift-part-2/" data-a2a-title="IoT edge development and deployment with containers through OpenShift: Part 2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/02/05/iot-edge-development-and-deployment-with-containers-through-openshift-part-2/"&gt;IoT edge development and deployment with containers through OpenShift: Part 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yFg4PldcTEw" height="1" width="1" alt=""/&gt;</content><summary>In the first part of this series, we saw how effective a platform as a service (PaaS) such as Red Hat OpenShift is for developing IoT edge applications and distributing them to remote sites, thanks to containers and Red Hat Ansible Automation technologies. Usually, we think about IoT applications as something specially designed for low power devices with limited capabilities.  IoT devices might us...</summary><dc:creator>Alessandro Arrichiello</dc:creator><dc:date>2019-02-05T13:00:49Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/02/05/iot-edge-development-and-deployment-with-containers-through-openshift-part-2/</feedburner:origLink></entry><entry><title>Annocheck: Examining the contents of binary files</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/vqQFFj5CD04/" /><category term="annobin" scheme="searchisko:content:tags" /><category term="annocheck" scheme="searchisko:content:tags" /><category term="binary files" scheme="searchisko:content:tags" /><category term="community" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="ELF" scheme="searchisko:content:tags" /><category term="fedora" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="gcc" scheme="searchisko:content:tags" /><category term="secur" scheme="searchisko:content:tags" /><category term="security" scheme="searchisko:content:tags" /><author><name>Nick Clifton</name></author><id>searchisko:content:id:jbossorg_blog-annocheck_examining_the_contents_of_binary_files</id><updated>2019-02-04T13:00:06Z</updated><published>2019-02-04T13:00:06Z</published><content type="html">&lt;p&gt;The &lt;a href="https://developers.redhat.com/blog/2018/02/20/annobin-storing-information-binaries/"&gt;Annobin plugin for GCC&lt;/a&gt; stores extra information inside binary files as they are compiled.  Examining this information used to be performed by a set of shell scripts, but that has now changed and a new program—annocheck—has been written to do the job.  The advantage of the program is that it is faster and more flexible than the scripts, and it does not rely upon other utilities to actually peer inside the binaries.&lt;/p&gt; &lt;p&gt;This article is about the annocheck program: how to use it, how it works, and how to extend it. The program&amp;#8217;s main purpose is to examine how a binary was built and to check that it has all of the appropriate security hardening features enabled. But that is not its only use.  It also has several other modes that perform different kinds of examination of binary files.&lt;/p&gt; &lt;p&gt;Another feature of annocheck is that it was designed to be easily extensible. It provides a framework for dissecting binary files and a set of utilities to help with this examination. It also knows how to handle archives, RPMs, and directories, presenting the contents of these to each tool as a series of ordinary files. Thus, tools need only worry about the specific tasks they want to carry out.&lt;/p&gt; &lt;p&gt;&lt;span id="more-557487"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Using annocheck&lt;/h2&gt; &lt;p&gt;Annocheck is supplied as part of the &lt;a href="https://rpmfind.net/linux/rpm2html/search.php?query=annobin"&gt;Annobin RPM shipped with Fedora&lt;/a&gt;. It can also be built directly from the source code obtained from the &lt;a href="http://git%20clone%20git://sourceware.org/git/annobin.git"&gt;git repository&lt;/a&gt;. The simplest way of running it is to just invoke it with the name of a file to inspect.  (Note: The file has to be an ELF format file.  Annocheck does not handle other binary file types.)&lt;/p&gt; &lt;pre&gt;annocheck &amp;#60;file&amp;#62;&lt;/pre&gt; &lt;p&gt;This command will run the default tool—the security hardening checker—on &lt;code&gt;&amp;#60;file&amp;#62;&lt;/code&gt;. The usual command-line options of &lt;code&gt;--help&lt;/code&gt;, &lt;code&gt;--version&lt;/code&gt;, and &lt;code&gt;--verbose&lt;/code&gt; are supported to provide more information. Annocheck also supports directories, archives, and RPMs, so all of the following will also work:&lt;/p&gt; &lt;pre&gt;annocheck &amp;#60;directory&amp;#62;&lt;/pre&gt; &lt;pre&gt;annocheck lib&amp;#60;foo&amp;#62;.a&lt;/pre&gt; &lt;pre&gt;annocheck &amp;#60;rpm&amp;#62;&lt;/pre&gt; &lt;p&gt;The first version will recursively run annocheck on all the ELF files inside &lt;code&gt;&amp;#60;directory&amp;#62;&lt;/code&gt;. (Other types of file will be ignored.) The second version will run annocheck on all the ELF files inside &lt;code&gt;lib&amp;#60;foo&amp;#62;.a&lt;/code&gt;. If this is a thin archive, the links inside the archive will be followed to find the real files.&lt;/p&gt; &lt;p&gt;The third version will run annocheck on all the ELF files inside &lt;code&gt;&amp;#60;rpm&amp;#62;&lt;/code&gt;. This version also supports a command-line option to provide the name of a debug info RPM associated with the binary RPM:&lt;/p&gt; &lt;pre&gt;annocheck &amp;#60;rpm&amp;#62; --debug-rpm &amp;#60;debuginfo rpm&amp;#62;&lt;/pre&gt; &lt;p&gt;Providing the debug info RPM is not essential, but it can be very helpful as it often contains information that makes the tool&amp;#8217;s work easier.&lt;/p&gt; &lt;p&gt;Annocheck contains multiple tools for examining binary files, although only the security hardening checker is enabled by default. The other tools can be enabled via specific command-line options. Currently, the extra tools that are supported by annocheck are as described below:&lt;/p&gt; &lt;pre&gt;annocheck --enable-built-by&lt;/pre&gt; &lt;p&gt;This tool reports the name of the compiler that was used to build the binary file. It looks in various different places in the binary, and if the &lt;code&gt;--all&lt;/code&gt; command-line option is present, it will report all the strings that it finds, instead of just the first one.&lt;/p&gt; &lt;pre&gt;annocheck --enable-notes&lt;/pre&gt; &lt;p&gt;This tool displays the notes that are stored inside a binary file by the Annobin GCC plugin. It is similar to the &lt;code&gt;readelf&lt;/code&gt; program&amp;#8217;s &lt;code&gt;--notes&lt;/code&gt; option, except that it sorts the notes by address range and then displays them sequentially.&lt;/p&gt; &lt;pre&gt;annocheck --section-size=&amp;#60;name&amp;#62;&lt;/pre&gt; &lt;p&gt;This tool displays the size of the named sections. It is similar to the &lt;code&gt;readelf&lt;/code&gt; program&amp;#8217;s &lt;code&gt;--sections&lt;/code&gt; option, except that the output is restricted to specific sections, and it produces a cumulative result at the end. Thus, for example, it could be used to compute the total size of all of the &lt;code&gt;.text&lt;/code&gt; sections in all the binary files inside a particular directory.&lt;/p&gt; &lt;p&gt;Each tool also has its own set of command-line options to modify its behavior. Use the &lt;code&gt;--help&lt;/code&gt; command-line option to see a full list of these. Multiple tools can be enabled at the same time, and the security hardening checker can be disabled, if desired, via the following option:&lt;/p&gt; &lt;pre&gt;annocheck --disable-hardened&lt;/pre&gt; &lt;h2&gt;The security hardening checker&lt;/h2&gt; &lt;p&gt;This is the largest, and arguably most important, tool in the annocheck framework. It runs a series of checks on each binary file to see if it has been built with the appropriate security hardening options. It obtains a lot of the information about these options via the notes generated by the Annobin plugin.&lt;/p&gt; &lt;p&gt;The security checker runs several tests to make sure that a program was linked correctly:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The program must not have a stack in an executable region of memory.&lt;/li&gt; &lt;li&gt;No segment in the program should have all three of the read, write, and execute permission bits set.&lt;/li&gt; &lt;li&gt;There should be no relocations against executable code.&lt;/li&gt; &lt;li&gt;The program must not have any relocations that are held in writable memory.&lt;/li&gt; &lt;li&gt;The runpath information used to locate shared libraries at runtime must include only directory paths that start with&lt;code&gt;/usr&lt;/code&gt;&lt;em&gt;.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;Dynamic executables must have a dynamic segment.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;-pie&lt;/code&gt; and &lt;code&gt;-z now&lt;/code&gt; linker options must have been enabled.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The security checker also runs tests on the Annobin data to make sure the program was compiled correctly:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The program must have Annobin notes, and there should be no gaps in the notes.&lt;/li&gt; &lt;li&gt;The program must have been compiled with the following options&lt;br /&gt; enabled:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-D_FORTIFY_SOURCE=2&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-fpic&lt;/code&gt; or &lt;code&gt;-fPIC&lt;/code&gt; or &lt;code&gt;-fpie&lt;/code&gt; or &lt;code&gt;-fPIE&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-fstack-protector-strong&lt;/code&gt; or &lt;code&gt;-fstack-protector-all&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-O2&lt;/code&gt; (or &lt;code&gt;-O3&lt;/code&gt; or &lt;code&gt;-Og&lt;/code&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Programs which use exception handling must have been compiled with &lt;code&gt;-fexceptions&lt;/code&gt; enabled and with &lt;code&gt;-D_GLIBCXX_ASSERTIONS&lt;/code&gt; specified.&lt;/li&gt; &lt;li&gt;If supported by the compiler, and appropriate for the specific target architecture, the following options must also have been enabled: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-fcf-protection=full&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-fstack-clash-protection&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-mcet&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-mstackrealign&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Extending annocheck&lt;/h2&gt; &lt;p&gt;Each tool in annocheck is provided by an independent source file (or set of source files) that is compiled and linked into the annocheck binary. Tools can be omitted by simply not including them on the final link command line. The annocheck framework does not have any built-in knowledge of any of the tools, and instead it interacts with them via a global structure that each tool creates for itself. The&lt;br /&gt; structure looks like this:&lt;/p&gt; &lt;pre&gt;struct {   const char * name;   bool (* process_arg)   void (* usage)   void (* version) void (* start_scan)   void (* end_scan)   bool (* start_file)   bool (* interesting_sec)   bool (* check_sec)   bool (* interesting_seg)   bool (* check_seg)   bool (* end_file) }&lt;/pre&gt; &lt;p&gt;This structure is defined in the &lt;code&gt;annocheck.h&lt;/code&gt; header file. The full details of the structure have been omitted here in order to keep things simple. The fields are mostly callback functions, except for the first—&lt;code&gt;name&lt;/code&gt;—which is the name of the tool. This name is used when reporting tool-specific information to the user.&lt;/p&gt; &lt;p&gt;The callback functions are the main part of the structure. The functions can be NULL if the tool does not need that particular feature. The &lt;code&gt;process_arg&lt;/code&gt;, &lt;code&gt;usage&lt;/code&gt;, and &lt;code&gt;version&lt;/code&gt; functions are part of the housekeeping facilities and are there to process command-line arguments, display help information, and display version information, respectively.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;start_scan&lt;/code&gt; function is called when annocheck starts up (although after the command-line arguments have been processed). Then once all the input files have been processed the &lt;code&gt;end_scan&lt;/code&gt; function is called. A quirk of the RPM format, however, means that it is necessary for annocheck to recursively invoke itself inside an RPM. This is allowed for in the &lt;code&gt;start_scan&lt;/code&gt; and &lt;code&gt;end_scan&lt;/code&gt; functions, which have a depth parameter and also the name of a file that can be used to pass information between invocation levels.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;start_file&lt;/code&gt; function is called after an individual binary file has been located, but before any processing has started. It gives the tool a chance to initialize any per-file data, and to decide if it is interested in processing the contents of the file. If the tool is not interested in the file, annocheck will not call any of the other per-file functions on it.&lt;/p&gt; &lt;p&gt;Once processing of a file has begun, the &lt;code&gt;interesting_sec&lt;/code&gt; callback is called for every section in the file. This allows the tool to decide if it wants to examine the section in more detail and, if so, the &lt;code&gt;check_sec&lt;/code&gt; callback will be called. The checking is done in this way so that if no tool is interested in a particular section, its contents are never loaded into memory, speeding up execution.&lt;/p&gt; &lt;p&gt;Once the sections have been processed—if there are any—the segments are scanned in a similar fashion using the &lt;code&gt;interesting_seg&lt;/code&gt; and &lt;code&gt;check_seg&lt;/code&gt; callbacks.&lt;/p&gt; &lt;p&gt;Once a file has been fully scanned, the &lt;code&gt;end_file&lt;/code&gt; callback is called in order to allow the tool to perform any final processing and display its results.&lt;/p&gt; &lt;p&gt;In addition to the callback structure, the &lt;code&gt;annocheck.h&lt;/code&gt; header also provides prototypes for all the utility functions exported by annocheck itself. This includes functions for exploring debug information and ELF notes, locating symbols, and printing out messages.&lt;/p&gt; &lt;p&gt;The header also defines a function to register a tool with the annocheck framework. This function is special in that it is expected to be called from inside a constructor, rather than from normal code. This is how tools tell annocheck about their existence, and it also allows annocheck to be built without any specific knowledge of any of the tools. The constructor function should look something like this:&lt;/p&gt; &lt;pre&gt;  static bool disabled = false; static __attribute__((constructor)) void tool_register_checker (void) {   if (! annocheck_add_checker (&amp;#38; tool_structure, major_version))      disabled = true; }&lt;/pre&gt; &lt;p&gt;In this function, &lt;code&gt;tool_structure&lt;/code&gt; is the callback structure described above. The &lt;code&gt;major_version&lt;/code&gt; variable is provided by annocheck, and it allows a consistency check to be made to ensure that both annocheck and the tool are using the same version of callback structure. If the &lt;code&gt;annocheck_add_checker&lt;/code&gt; function returns false, the tool should not execute any further, because something has gone wrong with the registration process.&lt;/p&gt; &lt;h2&gt;Future work&lt;/h2&gt; &lt;p&gt;Development of annocheck is an ongoing process with new features being added all the time.  Currently, the following enhancements are planned:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Add support for binary files inside tar files and, especially, inside compressed tar files. Possibly also add support for zip files and other, similar archive systems.&lt;/li&gt; &lt;li&gt;Improve the argument handling. Currently, each tool defines its own command-line options, and these can conflict with other tools. Instead, the annocheck framework ought to enforce a policy of supplying only specific options to specific tools.&lt;/li&gt; &lt;li&gt;Improve the notes tool to display a matrix of notes and the memory regions to which they apply. Also, add support for displaying section and function names that apply to specific regions.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#38;linkname=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F02%2F04%2Fannocheck-examining-the-contents-of-binary-files%2F&amp;#038;title=Annocheck%3A%20Examining%20the%20contents%20of%20binary%20files" data-a2a-url="https://developers.redhat.com/blog/2019/02/04/annocheck-examining-the-contents-of-binary-files/" data-a2a-title="Annocheck: Examining the contents of binary files"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/02/04/annocheck-examining-the-contents-of-binary-files/"&gt;Annocheck: Examining the contents of binary files&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/vqQFFj5CD04" height="1" width="1" alt=""/&gt;</content><summary>The Annobin plugin for GCC stores extra information inside binary files as they are compiled.  Examining this information used to be performed by a set of shell scripts, but that has now changed and a new program—annocheck—has been written to do the job.  The advantage of the program is that it is faster and more flexible than the scripts, and it does not rely upon other utilities to actually peer...</summary><dc:creator>Nick Clifton</dc:creator><dc:date>2019-02-04T13:00:06Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/02/04/annocheck-examining-the-contents-of-binary-files/</feedburner:origLink></entry><entry><title>jBPM Visual Studio Extension - New version 0.6.0 adds jBPM Business Apps debugging</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ydkSGHj4rU8/jbpm-visual-studio-extension-new.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Tihomir Surdilovic</name></author><id>searchisko:content:id:jbossorg_blog-jbpm_visual_studio_extension_new_version_0_6_0_adds_jbpm_business_apps_debugging</id><updated>2019-02-01T19:38:13Z</updated><published>2019-02-01T19:38:00Z</published><content type="html">Happy to announce a new 0.6.0 version of the &lt;b&gt;JBAVSC&lt;/b&gt; extension for &lt;b&gt;Visual Studio Code&lt;/b&gt;.&lt;br /&gt;&lt;br /&gt;This extension adds process &lt;b&gt;debugging&lt;/b&gt; for your business apps!&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-B8wkVX3O4R8/XFSe00XZaSI/AAAAAAAAhyY/4qceVpqh7tsUmdT_Se-GptaoJP62FlOaACLcBGAs/s1600/debugEditor.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="893" data-original-width="1600" height="222" src="https://1.bp.blogspot.com/-B8wkVX3O4R8/XFSe00XZaSI/AAAAAAAAhyY/4qceVpqh7tsUmdT_Se-GptaoJP62FlOaACLcBGAs/s400/debugEditor.png" width="400" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Debugging business app process in Visual Studio Code&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;br /&gt;JBAVSC Github:&amp;nbsp;https://github.com/BootstrapJBPM/jbavsc&lt;br /&gt;Visual Studio Code Marketplace:&amp;nbsp;&amp;nbsp;https://marketplace.visualstudio.com/items?itemName=tsurdilovic.jbavsc&lt;br /&gt;&lt;br /&gt;Here is a youtube vide showing off all the features of this extension:&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;iframe width="320" height="266" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/Ay_eJSvCyUM/0.jpg" src="https://www.youtube.com/embed/Ay_eJSvCyUM?feature=player_embedded" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;We can make this extension much much more powerful so if you are interested in helping please let us know!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ydkSGHj4rU8" height="1" width="1" alt=""/&gt;</content><summary>Happy to announce a new 0.6.0 version of the JBAVSC extension for Visual Studio Code. This extension adds process debugging for your business apps! Debugging business app process in Visual Studio Code JBAVSC Github: https://github.com/BootstrapJBPM/jbavsc Visual Studio Code Marketplace:  https://marketplace.visualstudio.com/items?itemName=tsurdilovic.jbavsc Here is a youtube vide showing off all t...</summary><dc:creator>Tihomir Surdilovic</dc:creator><dc:date>2019-02-01T19:38:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2019/02/jbpm-visual-studio-extension-new.html</feedburner:origLink></entry><entry><title>Modern Process Integration Tooling Workshop - Lab 3 Create a Domain Model</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/jiF5muSeXKw/modern-process-integration-tooling-workshop-lab3.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="workshops" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-modern_process_integration_tooling_workshop_lab_3_create_a_domain_model</id><updated>2019-02-01T06:00:01Z</updated><published>2019-02-01T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em; text-align: left;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://bpmworkshop.gitlab.io/index-redhat.html#/3" imageanchor="1" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;" target="_blank"&gt;&lt;img alt="process automation manager workshops" border="0" data-original-height="521" data-original-width="819" height="203" src="https://3.bp.blogspot.com/-H2LUVHDZXiI/XAfW1rJVeHI/AAAAAAAAtWU/z6mG0YikV6sCDhZDIamQo3Wd2ntzRl46wCLcBGAs/s320/Screenshot%2B2018-12-05%2Bat%2B14.45.32.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Click to start workshop&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div style="text-align: left;"&gt;&lt;/div&gt;Since starting to update my &lt;a href="https://bpmworkshop.gitlab.io/#/" target="_blank"&gt;free online rules and process automation workshops&lt;/a&gt; that showcase how to get started using modern business logic tooling, you've come a long ways with process automation.&lt;br /&gt;&lt;br /&gt;The updates started with moving from JBoss BPM&amp;nbsp; to Red Hat Decision Manager and from JBoss BPM Suite to Red Hat Process Automation Manager.&lt;br /&gt;&lt;br /&gt;This article highlights the newest lab update for Red Hat Process Automation Manager, where you learn to create a domain model.&lt;br /&gt;&lt;br /&gt;Let's take a look at the lab shall we?&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Lab 3 - Create a domain model&lt;/h3&gt;This lab is the latest step on learning to develop a process integration project. It's a step by step guide on how to create your first domain model.&lt;br /&gt;&lt;br /&gt;The easiest way is to just &lt;a href="https://bpmworkshop.gitlab.io/rhpam/lab03.html" target="_blank"&gt;jump right into lab 3&lt;/a&gt;:&lt;br /&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;iframe allowfullscreen="" frameborder="0" height="380" marginheight="0" marginwidth="0" scrolling="no" src="https://bpmworkshop.gitlab.io/rhpam/lab03.html" style="border-width: 1px; border: 1px solid #ccc; margin-bottom: 5px; max-width: 100%;" width="660"&gt;&lt;/iframe&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;Comments or feedback on any part of the workshop that might not be clear, just reach out.&lt;br /&gt;&lt;br /&gt;Stay tuned for the next lab update, coming soon!&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=sKifDDFrSUk:9OMuG60SSGc:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=sKifDDFrSUk:9OMuG60SSGc:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=sKifDDFrSUk:9OMuG60SSGc:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=sKifDDFrSUk:9OMuG60SSGc:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=sKifDDFrSUk:9OMuG60SSGc:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/sKifDDFrSUk" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/jiF5muSeXKw" height="1" width="1" alt=""/&gt;</content><summary>Click to start workshop Since starting to update my free online rules and process automation workshops that showcase how to get started using modern business logic tooling, you've come a long ways with process automation. The updates started with moving from JBoss BPM  to Red Hat Decision Manager and from JBoss BPM Suite to Red Hat Process Automation Manager. This article highlights the newest lab...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-02-01T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/sKifDDFrSUk/modern-process-integration-tooling-workshop-lab3.html</feedburner:origLink></entry><entry><title>Hibernate Search 6.0.0.Alpha2 and 5.11.1.Final released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/n1CLEizvIeU/" /><category term="elasticsearch" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="hibernate search" scheme="searchisko:content:tags" /><category term="lucene" scheme="searchisko:content:tags" /><category term="releases" scheme="searchisko:content:tags" /><author><name>Yoann Rodière</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_search_6_0_0_alpha2_and_5_11_1_final_released</id><updated>2019-02-06T12:07:30Z</updated><published>2019-02-01T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We just published Hibernate Search 5.11.1.Final, the first bugfix release for the stable 5.11 branch, as well as 6.0.0.Alpha2, the second release for the still-in-development 6.0 branch.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="getting-started-with-hibernate-search-6"&gt;&lt;a class="anchor" href="#getting-started-with-hibernate-search-6"&gt;&lt;/a&gt;Getting started with Hibernate Search 6&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you want to dive right into the new, shiny Hibernate Search 6, a good starting point is the &lt;a href="https://docs.jboss.org/hibernate/search/6.0/reference/en-US/html_single/#getting-started"&gt;getting started guide&lt;/a&gt; included in the reference documentation.&lt;/p&gt; &lt;/div&gt; &lt;div class="admonitionblock note"&gt; &lt;table&gt; &lt;tr&gt; &lt;td class="icon"&gt; &lt;i class="fa icon-note" title="Note"&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class="content"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Hibernate Search 6 is still in development and its APIs differ significantly from Search 5.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For more information about the current status of this branch, see &lt;a href="http://hibernate.org/search/releases/6.0/#whats-new"&gt;the page dedicated to Search 6 on hibernate.org&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For more information about migration and what we intend to do to help you, see &lt;a href="http://hibernate.org/search/documentation/migrate/6.0/"&gt;the migration guide&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="hibernate-search-6-at-fosdem"&gt;&lt;a class="anchor" href="#hibernate-search-6-at-fosdem"&gt;&lt;/a&gt;Hibernate Search 6 at FOSDEM&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you happen to be at FOSDEM in Brussels this weekend, you may be interested in &lt;a href="https://fosdem.org/2019/schedule/event/hibernate_search_6/"&gt;my talk about Hibernate Search 6&lt;/a&gt; in the Search devroom.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The presentation will be short (about 20 minutes + questions) and mainly aimed at Hibernate Search newcomers, but we can always have a talk afterwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-s-new"&gt;&lt;a class="anchor" href="#what-s-new"&gt;&lt;/a&gt;What’s new&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="5-11-1-final"&gt;&lt;a class="anchor" href="#5-11-1-final"&gt;&lt;/a&gt;5.11.1.Final&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Hibernate Search &lt;strong&gt;5.11.1.Final&lt;/strong&gt; mainly includes an upgrade to Hibernate ORM 5.4.1.Final (&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3470"&gt;HSEARCH-3470&lt;/a&gt;), which fixes a few major bugs.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For a full list of changes since the previous releases, please see the &lt;a href="https://hibernate.atlassian.net/secure/ReleaseNote.jspa?projectId=10061&amp;amp;version=31747"&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="6-0-0-alpha2"&gt;&lt;a class="anchor" href="#6-0-0-alpha2"&gt;&lt;/a&gt;6.0.0.Alpha2&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Here are some notable changes in Hibernate Search &lt;strong&gt;6.0.0.Alpha2&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Features ported from Search 5:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3052"&gt;HSEARCH-3052&lt;/a&gt;: Elasticsearch index lifecycle settings, including strategies (&lt;code&gt;create&lt;/code&gt;, &lt;code&gt;drop-and-create&lt;/code&gt;, &lt;code&gt;validate&lt;/code&gt;, …​) were ported from Search 5.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3268"&gt;HSEARCH-3268&lt;/a&gt;: The mass indexer was ported from Search 5.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3086"&gt;HSEARCH-3086&lt;/a&gt;: We added the remaining projections that were missing compared to Search 5: explanation (gives an explanation of scoring, for debugging purposes), document (projects on the whole document in Lucene), source (projects on the whole document in Elasticsearch).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3351"&gt;HSEARCH-3351&lt;/a&gt;: &lt;code&gt;FullTextQuery#getResultSize()&lt;/code&gt; was ported from Search 5.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improvements implying API changes:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3291"&gt;HSEARCH-3291&lt;/a&gt;: The field definition API, used in bridges, was split in two: type definition and field definition. This makes the API cleaner in &lt;code&gt;ValueBridge&lt;/code&gt;, and lays the groundwork for adding support for dynamic fields one day. This does make the API more verbose, but we intend to mitigate the issue in &lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3444"&gt;HSEARCH-3444&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3438"&gt;HSEARCH-3438&lt;/a&gt;: Type names and annotation names related to bridges and container extractors in the mapping should now be shorter and cleaner:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;@GenericField(extractors = @ContainerValueExtractorBeanReference(type = Foo.class))&lt;/code&gt; becomes &lt;code&gt;@GenericField(extractors = @ContainerExtractorRef(type = Foo.class))&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;@GenericField(valueBridge = @ValueBridgeBeanReference(type = Foo.class))&lt;/code&gt; becomes &lt;code&gt;@GenericField(valueBridge = @ValueBridgeRef(type = Foo.class))&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;…​ and similarly for other types and annotations.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3374"&gt;HSEARCH-3374&lt;/a&gt;: We switched back to the Search 5 syntax for including/excluding bounds in range predicates.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3416"&gt;HSEARCH-3416&lt;/a&gt;: Identifier predicates now correctly expect arguments of the type of the &lt;code&gt;@Id&lt;/code&gt;/&lt;code&gt;@DocumentId&lt;/code&gt; property, instead of always expecting strings.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3421"&gt;HSEARCH-3421&lt;/a&gt;: Identifier predicates now work correctly when multi-tenancy is enabled.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3101"&gt;HSEARCH-3101&lt;/a&gt;: The backend type in the settings no longer needs to be the fully-qualified name of an internal class: you can now simply use the strings "lucene" and "elasticsearch".&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3450"&gt;HSEARCH-3450&lt;/a&gt;: Several configuration properties, mainly in the Lucene backend, have been renamed for consistency. See the getting started guide for the new property names.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3451"&gt;HSEARCH-3451&lt;/a&gt;: Index defaults in configuration properties are now prefixed with &lt;code&gt;hibernate.search.backends.&amp;lt;name of the backend&amp;gt;.index_defaults.&lt;/code&gt;, instead of &lt;code&gt;hibernate.search.indexes.default.index_defaults.&lt;/code&gt;. This effectively means index defaults are defined on a per-backend basis, and not globally, allowing to use multiple backend types more easily.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3464"&gt;HSEARCH-3464&lt;/a&gt;: The &lt;code&gt;*Settings&lt;/code&gt; classes, holding property names for use when programmatically configuring Hibernate Search, have been renamed for consistency.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Other improvements and bug fixes:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3454"&gt;HSEARCH-3454&lt;/a&gt;: Upgrade to Lucene 7.6.0&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3472"&gt;HSEARCH-3472&lt;/a&gt;: Upgrade to Elasticsearch 6.6.0&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3470"&gt;HSEARCH-3470&lt;/a&gt;: Upgrade Hibernate ORM to 5.4.1.Final&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3174"&gt;HSEARCH-3174&lt;/a&gt;: For settings passed through programmatic APIs (for example the &lt;code&gt;java.util.Map&lt;/code&gt; passed to the JPA startup methods), Hibernate Search now also accepts values of the exact property type (integer, enum, …​) instead of only accepting Strings.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3429"&gt;HSEARCH-3429&lt;/a&gt;: The projection DSL now allows a lambda-based syntax consistent with the other DSLs.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3053"&gt;HSEARCH-3053&lt;/a&gt;: The full work orchestration mechanics of the Elasticsearch backend were ported from Search 5: performance is back to a production-grade level.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3453"&gt;HSEARCH-3453&lt;/a&gt;: Hibernate Search no longer executes blocking ORM-related operations in the Elasticsearch HTTP request pool, which could slow down the Elasticsearch backend dramatically.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH-3170"&gt;HSEARCH-3170&lt;/a&gt;: CDI/Spring beans are now released as soon as they are no longer needed, instead of being released on shutdown. This should bring some improvement for beans that are only needed during bootstrap, such as bridge builders or configurers.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For a full list of changes since the previous releases, please see the &lt;a href="https://hibernate.atlassian.net/secure/ReleaseNote.jspa?projectId=10061&amp;amp;version=31732"&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="how-to-get-these-releases"&gt;&lt;a class="anchor" href="#how-to-get-these-releases"&gt;&lt;/a&gt;How to get these releases&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;All details are available and up to date on the dedicated pages on hibernate.org:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://hibernate.org/search/releases/6.0/#get-it"&gt;this one for 6.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://hibernate.org/search/releases/5.11/#get-it"&gt;this one for 5.11&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="feedback-issues-ideas"&gt;&lt;a class="anchor" href="#feedback-issues-ideas"&gt;&lt;/a&gt;Feedback, issues, ideas?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To get in touch, use the following channels:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://stackoverflow.com/questions/tagged/hibernate-search"&gt;hibernate-search tag on Stackoverflow&lt;/a&gt; (usage questions)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/c/hibernate-search"&gt;User forum&lt;/a&gt; (usage questions, general feedback)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HSEARCH"&gt;Issue tracker&lt;/a&gt; (bug reports, feature requests)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://lists.jboss.org/pipermail/hibernate-dev/"&gt;Mailing list&lt;/a&gt; (development-related discussions)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/n1CLEizvIeU" height="1" width="1" alt=""/&gt;</content><summary>We just published Hibernate Search 5.11.1.Final, the first bugfix release for the stable 5.11 branch, as well as 6.0.0.Alpha2, the second release for the still-in-development 6.0 branch. Getting started with Hibernate Search 6 If you want to dive right into the new, shiny Hibernate Search 6, a good starting point is the getting started guide included in the reference documentation. Hibernate Searc...</summary><dc:creator>Yoann Rodière</dc:creator><dc:date>2019-02-01T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2019/02/01/hibernate-search-6-0-0-Alpha2-and-5-11-1-Final/</feedburner:origLink></entry></feed>
